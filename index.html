<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leitor de Cor em Tempo Real</title>
    <style>
        body { margin: 0; padding: 0; background-color: #000; }
        video { width: 100vw; height: 100vh; object-fit: cover; }
        .crosshair { position: absolute; top: 50%; left: 50%; width: 30px; height: 30px; border: 2px solid white; transform: translate(-50%, -50%); mix-blend-mode: difference; }
    </style>
</head>
<body>
    <video playsinline autoplay></video>
    <div class="crosshair"></div>
    <canvas style="display: none;"></canvas>

    <script>
        const video = document.querySelector('video');
        const canvas = document.querySelector('canvas');
        const context = canvas.getContext('2d', { willReadFrequently: true });
        let lastColorSent = '';

        // Função para converter RGB para um nome de cor básico
        function rgbToColorName(r, g, b) {
            // Limiares para preto, branco e cinza
            if (r < 40 && g < 40 && b < 40) return "preto";
            if (r > 220 && g > 220 && b > 220) return "branco";
            if (Math.abs(r - g) < 20 && Math.abs(g - b) < 20) return "cinza";

            // Limiares para cores primárias e secundárias
            if (r > g + 30 && r > b + 30) return "vermelho";
            if (g > r + 30 && g > b + 30) return "verde";
            if (b > r + 30 && b > g + 30) return "azul";
            if (r > 180 && g > 180 && b < 100) return "amarelo";
            if (r > 180 && g > 80 && b < 100) return "laranja";
            if (r > 150 && g < 100 && b > 150) return "rosa"; // ou roxo/magenta
            
            return ""; // Retorna vazio se não for uma cor clara
        }

        async function startCamera() {
            const constraints = { video: { facingMode: 'environment' } };
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                // Uma vez que o vídeo começa a tocar, iniciamos o loop de detecção
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    if (window.ReactNativeWebView) window.ReactNativeWebView.postMessage("camera_pronta");
                    requestAnimationFrame(detectColorLoop);
                };
            } catch (err) {
                console.error("Erro ao iniciar a câmera: ", err);
                if (window.ReactNativeWebView) window.ReactNativeWebView.postMessage("error:camera_falhou");
            }
        }

        function detectColorLoop() {
            // Desenha o frame do vídeo no canvas oculto
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            // Pega os dados do pixel do centro do canvas
            const pixelData = context.getImageData(canvas.width / 2, canvas.height / 2, 1, 1).data;
            const colorName = rgbToColorName(pixelData[0], pixelData[1], pixelData[2]);

            // Se a cor mudou desde a última vez, envia para o Thunkable
            if (colorName && colorName !== lastColorSent) {
                lastColorSent = colorName;
                if (window.ReactNativeWebView) {
                    window.ReactNativeWebView.postMessage("color:" + colorName);
                }
            }
            // Continua o loop
            requestAnimationFrame(detectColorLoop);
        }

        // Inicia o processo assim que a página carrega
        startCamera();
    </script>
</body>
</html>
